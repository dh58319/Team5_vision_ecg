{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 61.8 MB 258 kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17.0 in /home/donghyun/anaconda3/envs/ecg_env/lib/python3.8/site-packages (from opencv-python) (1.19.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/donghyun/anaconda3/envs/ecg_env/lib/python3.8/site-packages (from opencv-python) (1.19.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.7.0.72\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install einops\n",
    "# %pip install torch==1.12.1\n",
    "# %pip install torchvision==0.13.1\n",
    "# %pip install opencv-python"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- image_size: int.\n",
    "- Image size. If you have rectangular images, make sure your image size is the maximum of the width and - - height\n",
    "- patch_size: int.\n",
    "- Number of patches. image_size must be divisible by patch_size.\n",
    "- The number of patches is:  n = (image_size // patch_size) ** 2 and n must be greater than 16.\n",
    "- num_classes: int.\n",
    "- Number of classes to classify.\n",
    "- dim: int.\n",
    "- Last dimension of output tensor after linear transformation nn.Linear(..., dim).\n",
    "- depth: int.\n",
    "- Number of Transformer blocks.\n",
    "- heads: int.\n",
    "- Number of heads in Multi-head Attention layer.\n",
    "- mlp_dim: int.\n",
    "- Dimension of the MLP (FeedForward) layer.\n",
    "- channels: int, default 3.\n",
    "- Number of image's channels.\n",
    "- dropout: float between [0, 1], default 0..\n",
    "- Dropout rate.\n",
    "- emb_dropout: float between [0, 1], default 0.\n",
    "- Embedding dropout rate.\n",
    "- pool: string, either cls token pooling or mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/donghyun/workbench/git/VITpytorch')\n",
    "import torch\n",
    "from vit_pytorch import ViT\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the ViT model\n",
    "v = ViT(\n",
    "    image_size=256,\n",
    "    patch_size=32,\n",
    "    num_classes=1000,\n",
    "    dim=1024,\n",
    "    depth=6,\n",
    "    heads=16,\n",
    "    mlp_dim=2048,\n",
    "    dropout=0.1,\n",
    "    emb_dropout=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 256, 256)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open('/home/donghyun/workbench/results/pngfiles/00001.png')\n",
    "image = image.resize((256, 256))\n",
    "image_rgb = image.convert('RGB')  # Convert image to RGB format\n",
    "image_array = np.array(image_rgb)\n",
    "\n",
    "image_3d = np.moveaxis(image_array, -1, 0)[:3]  # Extract RGB channels and discard alpha channel if present\n",
    "image_4d = np.expand_dims(image_3d, axis=0)\n",
    "\n",
    "image_4d_tensor = torch.from_numpy(image_4d).float()\n",
    "preds = v(image_4d_tensor)  # Forward pass through the ViT model\n",
    "\n",
    "preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
